{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# `info_na()` Vignette \n",
                "\n",
                "In this section, we will explore the functionality of `info_na()`, a function with in `eda_mds` that expands the behaviour of `pd.DataFrame.info()`. \n",
                "We will do so by beginning the Exploratory Data Analysis process using both functions, and compare the output and necessary steps to acquire the same information, motivating its use.\n",
                "\n",
                "The dataset we will use is `titanic.csv` from the `seaborn` vignette dataset, available here: \n",
                "`https://github.com/mwaskom/seaborn-data/blob/master/titanic.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "from eda_mds import info_na\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Imagine we are beginning a new data science project. \n",
                "As with any project, exploratory data analysis (EDA) is a crucial first step to understand the nature of the data you are working with. \n",
                "\n",
                "\n",
                "A crucial part of EDA is determining the quality of your data. \n",
                "Missing datapoints can significantly affect model performance, largely causing them to break, and characterizing these values is essential to quantifying data quality. \n",
                "This will inform strategies to either remove, imput, or otherwise replace data with missing values. \n",
                "In some cases, specific rows or columns will be fragmented. Lets see how we can achieve this functionality using base `pandas`: "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 891 entries, 0 to 890\n",
                        "Data columns (total 15 columns):\n",
                        " #   Column       Non-Null Count  Dtype  \n",
                        "---  ------       --------------  -----  \n",
                        " 0   survived     891 non-null    int64  \n",
                        " 1   pclass       891 non-null    int64  \n",
                        " 2   sex          891 non-null    object \n",
                        " 3   age          714 non-null    float64\n",
                        " 4   sibsp        891 non-null    int64  \n",
                        " 5   parch        891 non-null    int64  \n",
                        " 6   fare         891 non-null    float64\n",
                        " 7   embarked     889 non-null    object \n",
                        " 8   class        891 non-null    object \n",
                        " 9   who          891 non-null    object \n",
                        " 10  adult_male   891 non-null    bool   \n",
                        " 11  deck         203 non-null    object \n",
                        " 12  embark_town  889 non-null    object \n",
                        " 13  alive        891 non-null    object \n",
                        " 14  alone        891 non-null    bool   \n",
                        "dtypes: bool(2), float64(2), int64(4), object(7)\n",
                        "memory usage: 92.4+ KB\n"
                    ]
                }
            ],
            "source": [
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "`pandas.DataFrame.info` is a great start! It shows us how many values in a dataset are non-null by column, alongside the data types. Here, we can see that some columns, particularly `deck`, are missing significant amounts of data. \n",
                "\n",
                "While this may seem like enough information at first glance, what about rows of data? How much data will be lost if we remove, say, all rows with null values? Is missing data randomly dispersed or is it focused in some rows? \n",
                "\n",
                "Lets see if we can answer these questions: "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "709 rows with any null value. (79.57%)\n"
                    ]
                }
            ],
            "source": [
                "n_rows_any_null = df.isna().any(axis=1).sum()\n",
                "n_rows = df.shape[0]\n",
                "print(f\"{n_rows_any_null} rows with any null value. ({n_rows_any_null / n_rows * 100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "80% is a huge amount of data! Thankfully, we can see that this is mostly in the column `deck`. \n",
                "\n",
                "Are there any rows that have more than one null value? Or rows that have all null values? "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0 rows have all-null values\n",
                        "0.98: average null values per row\n",
                        "2: max number of null values in a row\n"
                    ]
                }
            ],
            "source": [
                "n_rows_all_null = df.isna().all(axis=1).sum()\n",
                "mean_null_rows = df.isna().sum(axis=1).mean().round(2)\n",
                "max_null_rows = df.isna().sum(axis=1).max()\n",
                "\n",
                "print(f\"{n_rows_all_null} rows have all-null values\")\n",
                "print(f\"{mean_null_rows:0.2f}: average null values per row\")\n",
                "print(f\"{max_null_rows}: max number of null values in a row\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We've confirmed our suspicions, it appears that `deck` is the primary contributor for null values. \n",
                "\n",
                "In this case, we can see that the most amount of null values in any of the rows is two, and on average, we're missing one value in each row. \n",
                "\n",
                "\n",
                "This exercise shows the extra steps needed to more fully characterize a dataset. \n",
                "While this is not a huge amount of work, repeating this process for each project you begin will be tedious, and that's where `info_na` comes in: "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "type: <class 'pandas.core.frame.DataFrame'>\n",
                        "shape: (891, 15)\n",
                        "memory usage: 398.1 KB\n",
                        "--------\n",
                        "columns:\n",
                        " #      column  null count  null %   dtype\n",
                        " 0    survived           0    0.00   int64\n",
                        " 1      pclass           0    0.00   int64\n",
                        " 2         sex           0    0.00  object\n",
                        " 3         age         177   19.87 float64\n",
                        " 4       sibsp           0    0.00   int64\n",
                        " 5       parch           0    0.00   int64\n",
                        " 6        fare           0    0.00 float64\n",
                        " 7    embarked           2    0.22  object\n",
                        " 8       class           0    0.00  object\n",
                        " 9         who           0    0.00  object\n",
                        "10  adult_male           0    0.00    bool\n",
                        "11        deck         688   77.22  object\n",
                        "12 embark_town           2    0.22  object\n",
                        "13       alive           0    0.00  object\n",
                        "14       alone           0    0.00    bool\n",
                        "-----\n",
                        "rows:\n",
                        "total rows            891.00\n",
                        "any null count        709.00\n",
                        "any null %             79.57\n",
                        "all null count          0.00\n",
                        "all null %              0.00\n",
                        "mean null count         0.98\n",
                        "std.dev null count      0.62\n",
                        "max null count          2.00\n",
                        "min null count          0.00\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "info_na(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can see that many of the values we computed before (and some extra ones!) are provided, alongside the information given by `pandas.DataFrame.info`. \n",
                "\n",
                "This summarizes the primary use case of `info_na()`: characterizing missing values in a dataset in more detail - an essential task in most data science projects."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
